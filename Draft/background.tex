\section{Background}
\label{sec:background}
In this section we provide work related to security practices, measurement frameworks, and text mining.

\subsection{Measurement Frameworks}
Measurement frameworks offer a foundation for aggregating study results by standardizing the collection of empirical evidence, enabling comparison of results across projects. Previous researchers~\cite{kitchenham1999towards}, ~\cite{williams2004toward} have suggested four reasons for measurement frameworks: 
• To allow researchers to provide a context within which specific questions can be investigated;
• To help researchers understand and resolve contradictory results observed in empirical studies;
• to provide researchers a standard framework to assist in data collection and reporting of empirical studies in such a manner that they can be classified, understood, and replicated and to help industrial adoption of research results; and
• to provide researchers a framework for categorizing empirical studies into a body of knowledge.

Williams et al.~\cite{williams2004toward} defined a measurement framework for evaluating the use of Extreme Programming (XP), XP-EF. XP-EF contains context factors to capture internal project-related variables; adherence metrics to capture XP practice use; and outcome measures to capture external project results (e.g. quality). Modeled after XP-EF, we have developed SP-EF, a measurement framework for software development security practice use. We defined a similarly structured set of measures for recording context factors, practice adherence metrics, and outcome measures, related to the use of security practices in software development.
Rudolph and Schwartz~\cite{rudolph2012critical} conducted a systematic literature review, and Morrison et al.~\cite{morrison2014mapping} produced a technical report on security metrics. We chose the context factors and outcome measures aligned with the findings of these surveys.

The Common Vulnerability Scoring System~\cite{mell2006common} (CVSS) is a framework for communicating the characteristics of vulnerabilities in  (information technology (IT). Our focus is on the software development process and product rather than the individual vulnerability, however we adopt the Confidentiality Requirement, Integrity Requirement, and Availability Requirement elements of CVSS as context factors.

A number of organizations have published lists of security practices, including the Building Security in Maturity Model~\cite{mcgraw2013bsimm} (BSIMM), the Microsoft Security Development Lifecycle~\cite{howard2009security} (SDL), the Software Assurance Forum for Excellence in Code~\cite{simpson2013fundamental} (SAFECode), and the Open Web Application Security Project (OWASP) Software Security Assurance Process ~\cite{martinez2014ssap} (SSAP). Organizations and development teams may use one or more of these lists, however the lists do not specify how to go about choosing, implementing, monitoring, and assessing the effects of a set of security practices.
Mockus and Votta~\cite{mockus2000identifying} used keyword matching to distinguish between new code development, corrective, and perfective maintenance activities in version control system commit logs.

Cleland-Huang et al.~\cite{clelandhuang2006detection} applied classification to detect non-functional requirements in requirements documents, beginning with a keyword-based classification approach, refining the classifier to weight the keyword terms by their likelihood in each type of non-functional requirement. They achieved performance measures ranging from 20-100\% recall, and 3-92\% precision. We adapt their techniques by investigate the presence of practice use rather than the presence of non-functional requirements, and apply the techniques to the project version control system data, bug tracking data, and developer mailing lists, rather than to project specifications.

Ernst and Mylopoulos~\cite{ernst10refsq} applied keyword-based classification to evaluate the evolution of references to quality requirements over the life cycles of eight open-source projects. They did not find a systematic way in which references to quality requirements varied between the projects, and suggested that more refined techniques, e.g. domain-specific taxonomies, might be required to accurately track how requirements evolve in software projects. Our mining process parallels their `signifier extraction' process, however our search terms are drawn from SP-EF rather than generic requirements sources. They termed each occurrence of a requirement reference an `event', a convention we adopt in our work.

Hindle [29], building on Cleland-Huang et al.~\cite{clelandhuang2006detection} and Ernst and Mylopoulos~\cite{ernst10refsq} applied bag-of-words and topic modeling text-mining approaches to extracting software process events from project history data in project documentation, repositories, bug trackers, and mailing lists for FreeBSD and SQLLite, concluding that development practice use could be recovered from project history, although practices differ in how much evidence is available, and in the frequency of their occurrence. In following work, Hindle [30] used lists of quality keywords to categorize requirements topics in commit comments from MySQL and MaxDB repositories, using the data to visualize how attention to various requiments changes over the course of the project. Performance for topic recognition ranged between .07 and .93 Recall, and .09 and 1.0 Precision. 

Gegick et al. [31-cite] and Williams et al. [32-cite] have put forward lists of keywords related to security. We adopt these terms in our searches to identify potentially security-related issues, emails, and commits that are not marked by the project as security-related and that are not identified by our practice-specific keywords.
Bayesian Belief Networks share many similarities with SEM models, and have been explored in multiple ways in the software engineering literature[cite Fenton, Capra]. 

