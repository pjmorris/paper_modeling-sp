\section{Introduction}
\label{sec:intro}
In February 2017, security researchers discovered a programming bug in an HTML parser at Cloudflare\footnote{https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/}. The parser was sending decrypted encryption keys and passwords along with ordinary web requests, resulting in unencrypted sensitive data being cached across the Internet. While the programming bug, now known as `Cloudbleed'~\footnote{https://blog.cloudflare.com/quantifying-the-impact-of-cloudbleed}, was on a single line of code, the bug had widespread effects because of the code's context, running on many servers, and sending sensitive results to many clients. The example of Cloudbleed suggests that software development teams must consider software's environment and data as well as the technical characteristics of their software when evaluating their software's security. 

The IEEE defines security~\cite{ieee1990glossary} as 'all aspects related to defining, achieving, and maintaining confidentiality, integrity, availability, non-repudiation, accountability, authenticity, and reliability of a system.' Several lists of practices for specifying how a development team defines, achieves, and maintains the security properties listed above (confidentiality, integrity, availability, non-repudiation, accountability, authenticity, and reliability) in the software the team produces have been published. Example lists include the Building Security in Maturity Model ~\cite{mcgraw2006software}
(BSIMM), the Microsoft Security Development Lifecycle ~\cite{howard2009security} (SDL), the Software Assurance Forum for Excellence in Code~\cite{simpson2013fundamental} (SAFECode), and the Open Web Application Security Project (OWASP) Software Security Assurance Process ~\cite{martinez2014ssap} (SSAP). While defining how software will support the various security properties lies within the control of the development team, the observed security outcomes also depend on factors outside of the development team's direct control. Two pieces of software may have similar technical characteristics (e.g. same language, same size) but different security outcomes as a consequence of the uses to which the software is put. For example, between a game level editor and a database system of similar source code size, the database system managing credit card data may be more prone to attack, and to have publicly reported vulnerabilities~\footnote{Following Krsul~\cite{krsul1998software} and Ozment~\cite{ozment2007vulnerability}, we define a vulnerability as â€œan instance of a mistake in the specification, development, or configuration of software such that its execution can violate the explicit or implicit security policy.}, than the game level editor managing custom game levels. 

Multiple software technical and process characteristics contribute to the potential for software vulnerabilities. For example, code size ~\cite{alhazmi2007measuring}, code churn ~\cite{shin2011evaluating,meneely2013when}, and language ~\cite{ray2014a} have been correlated with vulnerabilities. Similarly, multiple software usage characteristics, for example, access to sensitive data~\footnote{http://heartbleed.com/}, management of financial information~\cite{harris2014for}, and the presence of a piece of software on large numbers of machines~\footnote{http://www.cert.org/historical/advisories/CA-2001-19.cfm} have been correlated with vulnerabilities. Finally, the practices a development team chooses to apply, and the degree to which they adhere to those practices, affects the number and kind of vulnerabilities in their software. As an example of a specific practice, teams may apply analysis tools like static analyzers and fuzzers to detecting code flaws before release. However, considerations like whether the team has been trained to use the tools, and whether the tools are regularly or occasionally applied will affect how effective the tools are in achieving security properties.  Two teams that use the same set of tools may differ in outcomes due to their degree of adherence to the practice of applying security tooling to their software. Development teams and researchers could benefit from a comprehensive picture of the factors underlying software security concerns.

\textit{The goal of this research is to support researchers and practitioners in measuring the effect of software context factors and security practice adherence on software security outcomes by building an explanatory model, and evaluating the model using structural equation modeling.}

We propose and evaluate a model, the \ModelName (\ModelAbbr), for quantifying security practice use and outcomes during software development. The four constructs of our model are:
\begin{enumerate}
	\item Software Development Context Factors (Development Risk) - measures of software characteristics that have been shown to be associated with vulnerabilities and defects;
	\item Software Usage Context Factors (Usage Risk) - measures of software usage characteristics associated with the value an attacker will find in conducting a successful attack;
	\item Practice Adherence (Adherence) - measures of the development team's security assurance efforts; 
	\item Security Outcomes (Outcomes) - measures of security-related indications (e.g. static analysis alerts, publicly reported vulnerabilities) associated with a piece of software over the course of the software's life cycle.
\end{enumerate}

We hypothesize that the four constructs are related as follows:
\begin{itemize}
	\item \textbf{H2} Usage Risk is associated with negative Security Outcomes
	\item \textbf{H1} Development Risk is associated with negative Security Outcomes
\item \textbf{H3} Development Risk is inversely associated with Practice Adherence  	
\end{itemize}
	
We conduct a case study of the construct relationships, applying data from OpenHub~\footnote{https://www.openhub.net/} and the National Vulnerability Database~\footnote{https://nvd.nist.gov/} (NVD) to evaluate the model and test our hypotheses.
  
Our contributions include:
\begin{itemize}
	\item A proposed model of the constructs affecting software development security outcomes;
	\item A proposed set of metrics for assessing security in the software development process, and
	\item Empirical evaluation of the proposed model and metrics using two open source datasets.
\end{itemize}
The remainder of this paper is organized as follows:  Section \ref{sec:background} discusses background and related work. Section \ref{sec:model} presents an overview of our model and its underlying hypotheses. Section \ref{sec:methodology} presents our study methodology. Section \ref{sec:evaluation_openhub} presents the case study and results. Section \ref{sec:discussion} discusses the case study results. Section \ref{sec:limitations} presents our study limitations. Section \ref{sec:conclusion} presents our conclusion.

