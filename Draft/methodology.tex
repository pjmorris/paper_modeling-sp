\section{Methodology}
\label{sec:methodology}

In this section, we present the steps required for analyzing a data set in terms of the security outcomes theoretical model.
\begin{itemize}
\item Subject Selection
Select a dataset containing measurements of variables that can be related to the structural model's Asset Value, Software Risk, adherence, and outcomes constructs.  

\item Link data source variables to model constructs 
Use theoretical relationships to link measurement model data source variables to structural model relationships. Consider each variable in the dataset, and assign eligible variables to the appropriate model construct. For example, if the dataset contains a code churn metric, associate it with the Software Risk construct. 

Standard SEM approaches assume linear relationships between variables in both structural and measurement models, requiring researchers to pre-examine the data for non-linear relationships. Potential solutions include excluding outliers and adding appropriate power terms.
 
\item Estimate SEM model 

Encode the combined structural and measurement models in a SEM modeling tool, and run the tool to obtain estimates for the model.
\item Report model fit measures recommended by Kline~\cite{kline2015principles}:
\begin{itemize}
	\item Model chi-square with degrees of freedom and p-value. Ratio of 3 or less for chi-square to degrees of freedom indicates acceptable fit.
	\item Stieger-Lind Root Mean Square Error of Approximation (RMSEA) - RMSEA is a `badness-of-fit' measure, where values less than 0.10 indicate acceptable fit.
	\item Bentler Comparative Fit Index (CFI) - CFI compares fit of the researcher's model to a baseline model, where values of 0.90 or greater are viewed as acceptable fit.
	\item Standardized Root Mean Square Residual (SRMR) - SRMR is a `badness-of-fit' measure of the difference between the observed and predicted correlations. Zero is a perfect score, scores below 0.08 are viewed as sufficient.
\end{itemize}

\item Model Fit and Re-specification
% TODO [Paragraph explaining model fit and indicators]

If model fit indicators show poor fit between the data and the model, consider adding, dropping, or moving measurement variables, if theory supports doing so. In the present study, we do not alter the constructs or relationships in the structural model, but we do allow a list of transformations for the measurement model, as follows:
\begin{itemize}
	\item Choice of measurement variable to construct association is at the discretion of the researcher. 
	\item Where more than one measurement variable measures the same concept (e.g. team size measured by a count and by an ordinal variable), variable choice is at the discretion of the researcher. 
	\item SEM requires measurement model variable variances to be within a narrow range of each other. Transforming a variable by taking its log, square root, or multiplying by a constant is at the discretion of the researcher (transformation must be documented).
\end{itemize} 

In addition to the global fit indicators presented above, researchers must examine residuals to assess local model fit. Residuals, also called error terms, are associated with each measurement variable, and represent variance not explained by the factor with which the measurement is associated. Residual values near zero indicate that the factor accounts for the bulk of the variance in the measurement variable. Residual values near one indicate that the factor does not account for the bulk of the variance in the measurement variable, and should prompt investigation, re-specification, and/or explanation. Residual values provide a diagnostic of model fit.

\item Report Results
% See page 464 of Kline for details
Report model fit in both the terms of the global fit indicators, and in terms of comparison between the expected theoretical relationships embedded in the model and the actual parameter magnitudes and signs observed in the data. In this work, we apply basic interpretations, focusing only on the sign and relative magnitude of each parameter estimate, as compared to our theorized expectations. For the parameter estimates of measurement variables associated with a single latent variable, sign indicates direction of influence, and (standardized) parameter estimates indicate the relative importance of each measurement variable's effect on the latent variable. For latent variable relationships, sign indicates the direction of influence, and magnitudes indicate the relative importance of the latent variable's effect on the receiving latent variable, as compared with the magnitude of the other latent variable parameter estimates.

\end{itemize}
